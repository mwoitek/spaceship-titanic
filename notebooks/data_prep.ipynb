{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0652ac1c-ce6a-4ba3-974e-b6f5aca7ae33",
   "metadata": {},
   "source": [
    "# Spaceship Titanic: Data Preparation\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed0436e-65f0-4d34-b88c-9e1782b654aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import cast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from pandas.testing import assert_frame_equal\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56deac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b43c669",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fba6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent / \"input\" / \"spaceship-titanic\"\n",
    "assert data_dir.exists(), f\"directory doesn't exist: {data_dir}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f33477d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0005_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/P</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sandie Hinetthews</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0006_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/2/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Billex Jacostaffey</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0006_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>28.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Candra Jacostaffey</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0007_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Andona Beston</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0008_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>B/1/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Erraiam Flatic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin    Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S    TRAPPIST-1e  16.0  False   \n",
       "5     0005_01      Earth     False  F/0/P  PSO J318.5-22  44.0  False   \n",
       "6     0006_01      Earth     False  F/2/S    TRAPPIST-1e  26.0  False   \n",
       "7     0006_02      Earth      True  G/0/S    TRAPPIST-1e  28.0  False   \n",
       "8     0007_01      Earth     False  F/3/S    TRAPPIST-1e  35.0  False   \n",
       "9     0008_01     Europa      True  B/1/P    55 Cancri e  14.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck                Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0     Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0        Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0       Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0        Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0   Willy Santantines   \n",
       "5          0.0      483.0           0.0   291.0     0.0   Sandie Hinetthews   \n",
       "6         42.0     1539.0           3.0     0.0     0.0  Billex Jacostaffey   \n",
       "7          0.0        0.0           0.0     0.0     NaN  Candra Jacostaffey   \n",
       "8          0.0      785.0          17.0   216.0     0.0       Andona Beston   \n",
       "9          0.0        0.0           0.0     0.0     0.0      Erraiam Flatic   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  \n",
       "5         True  \n",
       "6         True  \n",
       "7         True  \n",
       "8         True  \n",
       "9         True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "df_train = pd.read_csv(data_dir / \"train.csv\")\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7725e878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0027_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/7/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Karlen Ricks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0029_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>B/2/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>21.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Aldah Ainserfle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0032_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>D/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Acrabi Pringry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0032_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>D/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>23.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dhena Pringry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0033_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/7/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Eliana Delazarson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0013_01      Earth      True  G/3/S  TRAPPIST-1e  27.0  False   \n",
       "1     0018_01      Earth     False  F/4/S  TRAPPIST-1e  19.0  False   \n",
       "2     0019_01     Europa      True  C/0/S  55 Cancri e  31.0  False   \n",
       "3     0021_01     Europa     False  C/1/S  TRAPPIST-1e  38.0  False   \n",
       "4     0023_01      Earth     False  F/5/S  TRAPPIST-1e  20.0  False   \n",
       "5     0027_01      Earth     False  F/7/P  TRAPPIST-1e  31.0  False   \n",
       "6     0029_01     Europa      True  B/2/P  55 Cancri e  21.0  False   \n",
       "7     0032_01     Europa      True  D/0/S  TRAPPIST-1e  20.0  False   \n",
       "8     0032_02     Europa      True  D/0/S  55 Cancri e  23.0  False   \n",
       "9     0033_01      Earth     False  F/7/S  55 Cancri e  24.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \n",
       "0          0.0        0.0           0.0     0.0     0.0    Nelly Carsoning  \n",
       "1          0.0        9.0           0.0  2823.0     0.0     Lerome Peckers  \n",
       "2          0.0        0.0           0.0     0.0     0.0    Sabih Unhearfus  \n",
       "3          0.0     6652.0           0.0   181.0   585.0   Meratz Caltilter  \n",
       "4         10.0        0.0         635.0     0.0     0.0    Brence Harperez  \n",
       "5          0.0     1615.0         263.0   113.0    60.0       Karlen Ricks  \n",
       "6          0.0        NaN           0.0     0.0     0.0    Aldah Ainserfle  \n",
       "7          0.0        0.0           0.0     0.0     0.0     Acrabi Pringry  \n",
       "8          0.0        0.0           0.0     0.0     0.0      Dhena Pringry  \n",
       "9          0.0      639.0           0.0     0.0     0.0  Eliana Delazarson  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "df_test = pd.read_csv(data_dir / \"test.csv\")\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a09e9f",
   "metadata": {},
   "source": [
    "## New features from `PassengerId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be17841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group\n",
    "df_train[\"Group\"] = df_train.PassengerId.str.split(\"_\", expand=True).iloc[:, 0].astype(\"category\")\n",
    "df_test[\"Group\"] = df_test.PassengerId.str.split(\"_\", expand=True).iloc[:, 0].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d78fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alone and CompanionCount\n",
    "\n",
    "# Training data\n",
    "df_train = (\n",
    "    df_train.join(\n",
    "        df_train.groupby(by=\"Group\").PassengerId.count().rename(\"GroupSize\"),\n",
    "        on=\"Group\",\n",
    "    )\n",
    "    .assign(\n",
    "        Alone=lambda x: x.GroupSize == 1,\n",
    "        CompanionCount=lambda x: x.GroupSize - 1,\n",
    "    )\n",
    "    .drop(columns=\"GroupSize\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590fa297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "df_test = (\n",
    "    df_test.join(\n",
    "        df_test.groupby(by=\"Group\").PassengerId.count().rename(\"GroupSize\"),\n",
    "        on=\"Group\",\n",
    "    )\n",
    "    .assign(\n",
    "        Alone=lambda x: x.GroupSize == 1,\n",
    "        CompanionCount=lambda x: x.GroupSize - 1,\n",
    "    )\n",
    "    .drop(columns=\"GroupSize\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f821eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set indexes\n",
    "df_train = df_train.set_index(\"PassengerId\", verify_integrity=True)\n",
    "df_test = df_test.set_index(\"PassengerId\", verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6669421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine infrequent values of CompanionCount\n",
    "df_train = df_train.assign(\n",
    "    CompCntReduced=df_train.CompanionCount.transform(lambda x: np.where(x > 2, \"3+\", str(x)))\n",
    ").drop(columns=\"CompanionCount\")\n",
    "\n",
    "df_test = df_test.assign(\n",
    "    CompCntReduced=df_test.CompanionCount.transform(lambda x: np.where(x > 2, \"3+\", str(x)))\n",
    ").drop(columns=\"CompanionCount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9f641",
   "metadata": {},
   "source": [
    "## Impute some missing values of `HomePlanet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8e40bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passengers who belong to the same group also come from the same home planet\n",
    "df_test.loc[df_test.HomePlanet.notna(), [\"Group\", \"HomePlanet\"]].groupby(\n",
    "    \"Group\", observed=True\n",
    ").HomePlanet.nunique().eq(1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce501862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 201\n",
      "Test data: 87\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values BEFORE\n",
    "print(f\"Training data: {df_train.HomePlanet.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.HomePlanet.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa18430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "df_1 = (\n",
    "    df_train.loc[(df_train.Alone == False) & df_train.HomePlanet.notna(), [\"Group\", \"HomePlanet\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_2 = df_train.loc[\n",
    "    (df_train.Alone == False) & df_train.Group.isin(df_1.Group) & df_train.HomePlanet.isna(), [\"Group\"]\n",
    "].reset_index(drop=False)\n",
    "\n",
    "df_3 = df_2.merge(df_1, on=\"Group\").drop(columns=\"Group\").set_index(\"PassengerId\")\n",
    "# display(df_3.head(20))\n",
    "\n",
    "df_train.loc[df_3.index, \"HomePlanet\"] = df_3.HomePlanet\n",
    "# display(df_train.head(20))\n",
    "\n",
    "del df_1, df_2, df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac8234ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "df_1 = (\n",
    "    df_test.loc[(df_test.Alone == False) & df_test.HomePlanet.notna(), [\"Group\", \"HomePlanet\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_2 = df_test.loc[\n",
    "    (df_test.Alone == False) & df_test.Group.isin(df_1.Group) & df_test.HomePlanet.isna(), [\"Group\"]\n",
    "].reset_index(drop=False)\n",
    "\n",
    "df_3 = df_2.merge(df_1, on=\"Group\").drop(columns=\"Group\").set_index(\"PassengerId\")\n",
    "# display(df_3.head(20))\n",
    "\n",
    "df_test.loc[df_3.index, \"HomePlanet\"] = df_3.HomePlanet\n",
    "# display(df_test.head(20))\n",
    "\n",
    "del df_1, df_2, df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92eb4641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 111\n",
      "Test data: 46\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values AFTER\n",
    "print(f\"Training data: {df_train.HomePlanet.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.HomePlanet.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e6a18",
   "metadata": {},
   "source": [
    "## Using the `Name` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228b132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Surname column\n",
    "df_train = df_train.assign(Surname=df_train.Name.str.split(\" \", expand=True).iloc[:, 1]).drop(columns=\"Name\")\n",
    "df_test = df_test.assign(Surname=df_test.Name.str.split(\" \", expand=True).iloc[:, 1]).drop(columns=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f8cf1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passengers with the same surname are from the same planet\n",
    "df_test[[\"Surname\", \"HomePlanet\"]].dropna().groupby(\"Surname\").HomePlanet.nunique().eq(1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccaeef70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 111\n",
      "Test data: 46\n"
     ]
    }
   ],
   "source": [
    "# Use Surname to fill more missing HomePlanet values\n",
    "\n",
    "# Number of missing values BEFORE\n",
    "print(f\"Training data: {df_train.HomePlanet.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.HomePlanet.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e56d6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "df_sur_1 = (\n",
    "    df_train[[\"Surname\", \"HomePlanet\"]]\n",
    "    .dropna()\n",
    "    .groupby(\"Surname\")\n",
    "    .HomePlanet.first()\n",
    "    .to_frame()\n",
    "    .reset_index(drop=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f62d28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_train.loc[\n",
    "    df_train.Surname.notna() & df_train.Surname.isin(df_sur_1.Surname) & df_train.HomePlanet.isna(),\n",
    "    [\"Surname\"],\n",
    "].reset_index(drop=False)\n",
    "df_2 = df_1.merge(df_sur_1, on=\"Surname\").drop(columns=\"Surname\").set_index(\"PassengerId\")\n",
    "df_train.loc[df_2.index, \"HomePlanet\"] = df_2.HomePlanet\n",
    "del df_1, df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0930061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "df_sur_2 = (\n",
    "    df_test[[\"Surname\", \"HomePlanet\"]]\n",
    "    .dropna()\n",
    "    .groupby(\"Surname\")\n",
    "    .HomePlanet.first()\n",
    "    .to_frame()\n",
    "    .reset_index(drop=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab54544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency check\n",
    "assert_frame_equal(\n",
    "    df_sur_1.loc[df_sur_1.Surname.isin(df_sur_2.Surname), :].sort_values(\"Surname\").reset_index(drop=True),\n",
    "    df_sur_2.loc[df_sur_2.Surname.isin(df_sur_1.Surname), :].sort_values(\"Surname\").reset_index(drop=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdf6b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fix test data, I'll also use some training data. Combine all relevant data:\n",
    "df_sur = pd.concat(\n",
    "    [df_sur_1, df_sur_2.loc[~df_sur_2.Surname.isin(df_sur_1.Surname), :]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "del df_sur_1, df_sur_2\n",
    "assert df_sur.Surname.nunique() == df_sur.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c960e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_test.loc[\n",
    "    df_test.Surname.notna() & df_test.Surname.isin(df_sur.Surname) & df_test.HomePlanet.isna(),\n",
    "    [\"Surname\"],\n",
    "].reset_index(drop=False)\n",
    "df_2 = df_1.merge(df_sur, on=\"Surname\").drop(columns=\"Surname\").set_index(\"PassengerId\")\n",
    "df_test.loc[df_2.index, \"HomePlanet\"] = df_2.HomePlanet\n",
    "del df_1, df_2, df_sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80b2e3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 12\n",
      "Test data: 5\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values AFTER\n",
    "print(f\"Training data: {df_train.HomePlanet.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.HomePlanet.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717ae0d",
   "metadata": {},
   "source": [
    "## Impute some missing values of `VIP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90959cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No VIP passenger is from Earth\n",
    "df_train.loc[df_train.VIP.notna() & (df_train.VIP == True) & df_train.HomePlanet.notna(), \"HomePlanet\"].ne(\n",
    "    \"Earth\"\n",
    ").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc47d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 203\n",
      "Test data: 93\n"
     ]
    }
   ],
   "source": [
    "# Use HomePlanet to fill some missing VIP values\n",
    "\n",
    "# Number of missing values BEFORE\n",
    "print(f\"Training data: {df_train.VIP.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.VIP.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba17fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.VIP.isna() & df_train.HomePlanet.notna() & (df_train.HomePlanet == \"Earth\"), \"VIP\"] = (\n",
    "    False\n",
    ")\n",
    "df_test.loc[df_test.VIP.isna() & df_test.HomePlanet.notna() & (df_test.HomePlanet == \"Earth\"), \"VIP\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff15e227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 86\n",
      "Test data: 49\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values AFTER\n",
    "print(f\"Training data: {df_train.VIP.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.VIP.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e79c28",
   "metadata": {},
   "source": [
    "## Encode `HomePlanet` and `Destination`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6d16b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Earth', 'Europa', 'Mars', nan], dtype=object)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert HomePlanet to ordinal integers\n",
    "enc = OrdinalEncoder().fit(df_train[[\"HomePlanet\"]])\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95eeff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"HomePlanetOrd\"] = enc.transform(df_train[[\"HomePlanet\"]]).flatten()\n",
    "df_test[\"HomePlanetOrd\"] = enc.transform(df_test[[\"HomePlanet\"]]).flatten()\n",
    "del enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f06b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>HomePlanetOrd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002_01</th>\n",
       "      <td>Earth</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_01</th>\n",
       "      <td>Europa</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009_01</th>\n",
       "      <td>Mars</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            HomePlanet  HomePlanetOrd\n",
       "PassengerId                          \n",
       "0002_01          Earth            0.0\n",
       "0003_01         Europa            1.0\n",
       "0009_01           Mars            2.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[[\"0002_01\", \"0003_01\", \"0009_01\"], [\"HomePlanet\", \"HomePlanetOrd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0bfe78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency checks\n",
    "assert df_train.loc[df_train.HomePlanet.isna(), \"HomePlanetOrd\"].isna().all()\n",
    "assert df_train.loc[df_train.HomePlanet.notna(), \"HomePlanetOrd\"].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fbf3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_test.loc[df_test.HomePlanet.isna(), \"HomePlanetOrd\"].isna().all()\n",
    "assert df_test.loc[df_test.HomePlanet.notna(), \"HomePlanetOrd\"].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0d5a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['55 Cancri e', 'PSO J318.5-22', 'TRAPPIST-1e', nan], dtype=object)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Destination to ordinal integers\n",
    "enc = OrdinalEncoder().fit(df_train[[\"Destination\"]])\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21ddb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"DestinationOrd\"] = enc.transform(df_train[[\"Destination\"]]).flatten()\n",
    "df_test[\"DestinationOrd\"] = enc.transform(df_test[[\"Destination\"]]).flatten()\n",
    "del enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3b8d763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>DestinationOrd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0008_01</th>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005_01</th>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001_01</th>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Destination  DestinationOrd\n",
       "PassengerId                               \n",
       "0008_01        55 Cancri e             0.0\n",
       "0005_01      PSO J318.5-22             1.0\n",
       "0001_01        TRAPPIST-1e             2.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[[\"0008_01\", \"0005_01\", \"0001_01\"], [\"Destination\", \"DestinationOrd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66b6c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency checks\n",
    "assert df_train.loc[df_train.Destination.isna(), \"DestinationOrd\"].isna().all()\n",
    "assert df_train.loc[df_train.Destination.notna(), \"DestinationOrd\"].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a2eca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_test.loc[df_test.Destination.isna(), \"DestinationOrd\"].isna().all()\n",
    "assert df_test.loc[df_test.Destination.notna(), \"DestinationOrd\"].notna().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f871ca",
   "metadata": {},
   "source": [
    "## More simple data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "489eba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RoomService      82\n",
       "FoodCourt       106\n",
       "ShoppingMall     98\n",
       "Spa             101\n",
       "VRDeck           80\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The \"money features\" are dominated by zeros. Then it's reasonable to fill all\n",
    "# of their missing values with zero.\n",
    "cols = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "\n",
    "# Number of missing values BEFORE\n",
    "print(\"Training data:\")\n",
    "display(df_train[cols].isna().sum())\n",
    "\n",
    "print(\"Test data:\")\n",
    "display(df_test[cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b9c9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:, cols] = df_train[cols].fillna(0.0)\n",
    "df_test.loc[:, cols] = df_test[cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37732c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalSpent\n",
    "df_train[\"TotalSpent\"] = df_train[cols].agg(\"sum\", axis=1)\n",
    "df_test[\"TotalSpent\"] = df_test[cols].agg(\"sum\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f77b423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 217\n",
      "Test data: 93\n"
     ]
    }
   ],
   "source": [
    "# Fill some missing CryoSleep values based on TotalSpent\n",
    "\n",
    "# Number of missing values BEFORE\n",
    "print(f\"Training data: {df_train.CryoSleep.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.CryoSleep.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c9f2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.CryoSleep.isna() & df_train.TotalSpent.gt(0.0), \"CryoSleep\"] = False\n",
    "df_test.loc[df_test.CryoSleep.isna() & df_test.TotalSpent.gt(0.0), \"CryoSleep\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f1ee792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 98\n",
      "Test data: 38\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values AFTER\n",
    "print(f\"Training data: {df_train.CryoSleep.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.CryoSleep.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fb0c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passengers who were in cryo sleep spent NO MONEY\n",
    "assert df_train.loc[df_train.CryoSleep.notna() & (df_train.CryoSleep == True), cols].eq(0.0).all(axis=None)\n",
    "assert df_test.loc[df_test.CryoSleep.notna() & (df_test.CryoSleep == True), cols].eq(0.0).all(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ba649",
   "metadata": {},
   "source": [
    "## New features from \"money variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec751567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original money variables will be replaced with binary features. They indicate\n",
    "# when the original variables were strictly positive.\n",
    "df_train = df_train.join(df_train[cols].gt(0.0).rename(columns={col: f\"Pos{col}\" for col in cols})).drop(\n",
    "    columns=cols\n",
    ")\n",
    "df_test = df_test.join(df_test[cols].gt(0.0).rename(columns={col: f\"Pos{col}\" for col in cols})).drop(\n",
    "    columns=cols\n",
    ")\n",
    "del cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7a8628c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06549240721181425"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Power transformation of TotalSpent\n",
    "transformer = PowerTransformer().fit(df_train[[\"TotalSpent\"]])\n",
    "transformer.lambdas_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0433f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(PTTotalSpent=transformer.transform(df_train[[\"TotalSpent\"]]).flatten()).drop(\n",
    "    columns=\"TotalSpent\"\n",
    ")\n",
    "df_test = df_test.assign(PTTotalSpent=transformer.transform(df_test[[\"TotalSpent\"]]).flatten()).drop(\n",
    "    columns=\"TotalSpent\"\n",
    ")\n",
    "del transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15702bf",
   "metadata": {},
   "source": [
    "## New features from `Cabin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcec1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CabinDeck, CabinNum and CabinSide\n",
    "df_train = df_train.join(\n",
    "    df_train.Cabin.str.split(\"/\", expand=True).rename(columns={0: \"CabinDeck\", 1: \"CabinNum\", 2: \"CabinSide\"})\n",
    ").drop(columns=\"Cabin\")\n",
    "\n",
    "df_test = df_test.join(\n",
    "    df_test.Cabin.str.split(\"/\", expand=True).rename(columns={0: \"CabinDeck\", 1: \"CabinNum\", 2: \"CabinSide\"})\n",
    ").drop(columns=\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69e2ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CabinDeck: Combine three categories into one\n",
    "df_train.loc[df_train.CabinDeck.notna() & df_train.CabinDeck.isin([\"D\", \"A\", \"T\"]), \"CabinDeck\"] = \"Other\"\n",
    "df_test.loc[df_test.CabinDeck.notna() & df_test.CabinDeck.isin([\"D\", \"A\", \"T\"]), \"CabinDeck\"] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36b9f67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['B', 'C', 'E', 'F', 'G', 'Other', nan], dtype=object)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to ordinal integers\n",
    "enc = OrdinalEncoder().fit(df_train[[\"CabinDeck\"]])\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b1b096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"CabinDeckOrd\"] = enc.transform(df_train[[\"CabinDeck\"]]).flatten()\n",
    "df_test[\"CabinDeckOrd\"] = enc.transform(df_test[[\"CabinDeck\"]]).flatten()\n",
    "del enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9769c937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinDeckOrd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0001_01</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0024_01</th>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020_01</th>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002_01</th>\n",
       "      <td>F</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0006_02</th>\n",
       "      <td>G</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003_01</th>\n",
       "      <td>Other</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CabinDeck  CabinDeckOrd\n",
       "PassengerId                        \n",
       "0001_01             B           0.0\n",
       "0024_01             C           1.0\n",
       "0020_01             E           2.0\n",
       "0002_01             F           3.0\n",
       "0006_02             G           4.0\n",
       "0003_01         Other           5.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[\n",
    "    [\"0001_01\", \"0024_01\", \"0020_01\", \"0002_01\", \"0006_02\", \"0003_01\"],\n",
    "    [\"CabinDeck\", \"CabinDeckOrd\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17c3c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency checks\n",
    "assert df_train.loc[df_train.CabinDeck.isna(), \"CabinDeckOrd\"].isna().all()\n",
    "assert df_train.loc[df_train.CabinDeck.notna(), \"CabinDeckOrd\"].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a568cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_test.loc[df_test.CabinDeck.isna(), \"CabinDeckOrd\"].isna().all()\n",
    "assert df_test.loc[df_test.CabinDeck.notna(), \"CabinDeckOrd\"].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b49ac066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=\"CabinDeck\")\n",
    "df_test = df_test.drop(columns=\"CabinDeck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66ba243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 199\n",
      "Test data: 100\n"
     ]
    }
   ],
   "source": [
    "# Fill some missing CabinSide values using group data\n",
    "# Passengers that belong to the same group were on the same side of the spaceship\n",
    "\n",
    "# Number of missing values BEFORE\n",
    "print(f\"Training data: {df_train.CabinSide.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.CabinSide.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b310c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "df_1 = (\n",
    "    df_train.loc[(df_train.Alone == False) & df_train.CabinSide.notna(), [\"CabinSide\", \"Group\"]]\n",
    "    .groupby(\"Group\", observed=True)\n",
    "    .CabinSide.first()\n",
    "    .to_frame()\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df_2 = df_train.loc[(df_train.Alone == False) & df_train.CabinSide.isna(), [\"Group\"]].reset_index(drop=False)\n",
    "df_3 = df_2.merge(df_1, on=\"Group\").drop(columns=\"Group\").set_index(\"PassengerId\")\n",
    "df_train.loc[df_3.index, \"CabinSide\"] = df_3.CabinSide\n",
    "del df_1, df_2, df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "908ff969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "df_1 = (\n",
    "    df_test.loc[(df_test.Alone == False) & df_test.CabinSide.notna(), [\"CabinSide\", \"Group\"]]\n",
    "    .groupby(\"Group\", observed=True)\n",
    "    .CabinSide.first()\n",
    "    .to_frame()\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "df_2 = df_test.loc[(df_test.Alone == False) & df_test.CabinSide.isna(), [\"Group\"]].reset_index(drop=False)\n",
    "df_3 = df_2.merge(df_1, on=\"Group\").drop(columns=\"Group\").set_index(\"PassengerId\")\n",
    "df_test.loc[df_3.index, \"CabinSide\"] = df_3.CabinSide\n",
    "del df_1, df_2, df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fd16384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 99\n",
      "Test data: 63\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values AFTER\n",
    "print(f\"Training data: {df_train.CabinSide.isna().sum()}\")\n",
    "print(f\"Test data: {df_test.CabinSide.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d36c6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CabinSide to a boolean feature\n",
    "df_train[\"CabinPort\"] = np.nan\n",
    "df_train.loc[df_train.CabinSide.notna(), \"CabinPort\"] = (\n",
    "    df_train.loc[df_train.CabinSide.notna(), \"CabinSide\"] == \"P\"\n",
    ")\n",
    "df_train = df_train.drop(columns=\"CabinSide\")\n",
    "\n",
    "df_test[\"CabinPort\"] = np.nan\n",
    "df_test.loc[df_test.CabinSide.notna(), \"CabinPort\"] = (\n",
    "    df_test.loc[df_test.CabinSide.notna(), \"CabinSide\"] == \"P\"\n",
    ")\n",
    "df_test = df_test.drop(columns=\"CabinSide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710cad6",
   "metadata": {},
   "source": [
    "## Discretize `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5892973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0., 19., 27., 38., 79.])], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discretize using quantiles and 4 bins\n",
    "discretizer = KBinsDiscretizer(n_bins=4, strategy=\"quantile\", encode=\"ordinal\", random_state=333).fit(\n",
    "    df_train.loc[df_train.Age.notna(), [\"Age\"]]\n",
    ")\n",
    "discretizer.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f038da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"DiscretizedAge4\"] = np.nan\n",
    "df_train.loc[df_train.Age.notna(), \"DiscretizedAge4\"] = discretizer.transform(\n",
    "    df_train.loc[df_train.Age.notna(), [\"Age\"]]\n",
    ")\n",
    "\n",
    "df_test[\"DiscretizedAge4\"] = np.nan\n",
    "df_test.loc[df_test.Age.notna(), \"DiscretizedAge4\"] = discretizer.transform(\n",
    "    df_test.loc[df_test.Age.notna(), [\"Age\"]]\n",
    ")\n",
    "\n",
    "del discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6c4724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0., 18., 24., 31., 41., 79.])], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discretize using quantiles and 5 bins\n",
    "discretizer = KBinsDiscretizer(n_bins=5, strategy=\"quantile\", encode=\"ordinal\", random_state=333).fit(\n",
    "    df_train.loc[df_train.Age.notna(), [\"Age\"]]\n",
    ")\n",
    "discretizer.bin_edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "338e61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"DiscretizedAge5\"] = np.nan\n",
    "df_train.loc[df_train.Age.notna(), \"DiscretizedAge5\"] = discretizer.transform(\n",
    "    df_train.loc[df_train.Age.notna(), [\"Age\"]]\n",
    ")\n",
    "\n",
    "df_test[\"DiscretizedAge5\"] = np.nan\n",
    "df_test.loc[df_test.Age.notna(), \"DiscretizedAge5\"] = discretizer.transform(\n",
    "    df_test.loc[df_test.Age.notna(), [\"Age\"]]\n",
    ")\n",
    "\n",
    "del discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7542377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=\"Age\")\n",
    "df_test = df_test.drop(columns=\"Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9cbdc0",
   "metadata": {},
   "source": [
    "## Organize DataFrames and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f39946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_rm = [\n",
    "    \"CabinNum\",\n",
    "    \"Destination\",\n",
    "    \"Group\",\n",
    "    \"HomePlanet\",\n",
    "    \"Surname\",\n",
    "]\n",
    "df_train = df_train.drop(columns=cols_rm)\n",
    "df_test = df_test.drop(columns=cols_rm)\n",
    "del cols_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c826de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_keep = [\n",
    "    \"Alone\",\n",
    "    \"CompCntReduced\",\n",
    "    \"HomePlanetOrd\",\n",
    "    \"CryoSleep\",\n",
    "    \"CabinDeckOrd\",\n",
    "    \"CabinPort\",\n",
    "    \"DestinationOrd\",\n",
    "    \"DiscretizedAge4\",\n",
    "    \"DiscretizedAge5\",\n",
    "    \"VIP\",\n",
    "    \"PosRoomService\",\n",
    "    \"PosFoodCourt\",\n",
    "    \"PosShoppingMall\",\n",
    "    \"PosSpa\",\n",
    "    \"PosVRDeck\",\n",
    "    \"PTTotalSpent\",\n",
    "    \"Transported\",\n",
    "]\n",
    "df_train = df_train[cols_keep]\n",
    "cols_keep.pop()\n",
    "df_test = df_test[cols_keep]\n",
    "del cols_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01ea634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cast(pd.DataFrame, df_train)\n",
    "df_test = cast(pd.DataFrame, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4467eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8693 entries, 0001_01 to 9280_02\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Alone            8693 non-null   bool   \n",
      " 1   CompCntReduced   8693 non-null   object \n",
      " 2   HomePlanetOrd    8681 non-null   float64\n",
      " 3   CryoSleep        8595 non-null   object \n",
      " 4   CabinDeckOrd     8494 non-null   float64\n",
      " 5   CabinPort        8594 non-null   object \n",
      " 6   DestinationOrd   8511 non-null   float64\n",
      " 7   DiscretizedAge4  8514 non-null   float64\n",
      " 8   DiscretizedAge5  8514 non-null   float64\n",
      " 9   VIP              8607 non-null   object \n",
      " 10  PosRoomService   8693 non-null   bool   \n",
      " 11  PosFoodCourt     8693 non-null   bool   \n",
      " 12  PosShoppingMall  8693 non-null   bool   \n",
      " 13  PosSpa           8693 non-null   bool   \n",
      " 14  PosVRDeck        8693 non-null   bool   \n",
      " 15  PTTotalSpent     8693 non-null   float64\n",
      " 16  Transported      8693 non-null   bool   \n",
      "dtypes: bool(7), float64(6), object(4)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59f7c813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alone                0\n",
       "CompCntReduced       0\n",
       "HomePlanetOrd       12\n",
       "CryoSleep           98\n",
       "CabinDeckOrd       199\n",
       "CabinPort           99\n",
       "DestinationOrd     182\n",
       "DiscretizedAge4    179\n",
       "DiscretizedAge5    179\n",
       "VIP                 86\n",
       "PosRoomService       0\n",
       "PosFoodCourt         0\n",
       "PosShoppingMall      0\n",
       "PosSpa               0\n",
       "PosVRDeck            0\n",
       "PTTotalSpent         0\n",
       "Transported          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f36cde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4277 entries, 0013_01 to 9277_01\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Alone            4277 non-null   bool   \n",
      " 1   CompCntReduced   4277 non-null   object \n",
      " 2   HomePlanetOrd    4272 non-null   float64\n",
      " 3   CryoSleep        4239 non-null   object \n",
      " 4   CabinDeckOrd     4177 non-null   float64\n",
      " 5   CabinPort        4214 non-null   object \n",
      " 6   DestinationOrd   4185 non-null   float64\n",
      " 7   DiscretizedAge4  4186 non-null   float64\n",
      " 8   DiscretizedAge5  4186 non-null   float64\n",
      " 9   VIP              4228 non-null   object \n",
      " 10  PosRoomService   4277 non-null   bool   \n",
      " 11  PosFoodCourt     4277 non-null   bool   \n",
      " 12  PosShoppingMall  4277 non-null   bool   \n",
      " 13  PosSpa           4277 non-null   bool   \n",
      " 14  PosVRDeck        4277 non-null   bool   \n",
      " 15  PTTotalSpent     4277 non-null   float64\n",
      "dtypes: bool(6), float64(6), object(4)\n",
      "memory usage: 521.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d790522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alone                0\n",
       "CompCntReduced       0\n",
       "HomePlanetOrd        5\n",
       "CryoSleep           38\n",
       "CabinDeckOrd       100\n",
       "CabinPort           63\n",
       "DestinationOrd      92\n",
       "DiscretizedAge4     91\n",
       "DiscretizedAge5     91\n",
       "VIP                 49\n",
       "PosRoomService       0\n",
       "PosFoodCourt         0\n",
       "PosShoppingMall      0\n",
       "PosSpa               0\n",
       "PosVRDeck            0\n",
       "PTTotalSpent         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "992a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(data_dir / \"train_prep.csv\", index=True)\n",
    "df_test.to_csv(data_dir / \"test_prep.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
